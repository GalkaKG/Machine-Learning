{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08f3d5fb-28b6-48a6-827e-8a8eb3f48cb8",
   "metadata": {},
   "source": [
    "# Review of Article: Machine Learning Renormalization Group for Statistical Physics\n",
    "\n",
    "\n",
    "Link to article: https://arxiv.org/pdf/2306.11054v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ac35d2-d1bb-4e6e-9f47-e55970247f3a",
   "metadata": {},
   "source": [
    "### Authors\n",
    "- Wanda Hou and Yi-Zhuang You,\n",
    "_Department of Physics, University of California at San Diego, La Jolla, CA 92093, USA_\n",
    "\n",
    "### Problem Addressed\n",
    "The article addresses the challenge of efficiently applying the Renormalization Group (RG) methods in statistical physics to identify critical points and analyze complex physical systems. Traditional methods, such as Monte Carlo simulations and tensor-network techniques, face limitations in computational efficiency and accuracy, particularly when dealing with large parameter spaces and intricate models. The authors propose a novel approach called the __Multi-Level Renormalization Group (MLRG)__, which incorporates a machine learning framework to improve the discovery of RG transformations and critical points while reducing computational costs.\n",
    "\n",
    "\n",
    "### Methods Used\n",
    "1. The authors introduce the Multi-Level Renormalization Group (MLRG) approach, which integrates multiple models—specifically, a teacher model, a student model, and a moderator model—into a cohesive framework for RG analysis. The methodology can be summarized as follows:\n",
    "\n",
    "2. Multi-Model Design: The MLRG framework consists of a teacher model that provides knowledge about the RG flow, a student model that learns from the teacher, and a moderator model that guides the sampling of new model parameters. This hierarchical structure allows for efficient knowledge extraction and error correction.\n",
    "\n",
    "3. Stochastic Sampling: The MLRG employs Gibbs sampling within small clusters of spins, leveraging specific lattice structures (e.g., the Lieb lattice) to optimize the RG transformations. This design enables the algorithm to operate efficiently on a smaller scale compared to traditional methods.\n",
    "\n",
    "4. Machine Learning Integration: The approach utilizes machine learning techniques to optimize RG transformations by minimizing the discrepancy between the teacher and student models. This involves defining optimal RG transformations based on the match of marginal distributions between the two models.\n",
    "\n",
    "5. Automated Discovery of Critical Points: The MLRG algorithm identifies critical points by leveraging the learned RG flow and calculating fixed-point properties, thereby circumventing the need for finite-size scaling.\n",
    "\n",
    "6. Parallelization and Computational Efficiency: The methodology is designed to allow parallelization across multiple spin clusters, enhancing computational efficiency and enabling the exploration of the entire parameter space in a single training pass.\n",
    "\n",
    "\n",
    "### Key Findings:\n",
    "1. Efficiency of MLRG: The MLRG approach demonstrates superior efficiency in sampling spin configurations within small clusters compared to traditional Monte Carlo simulations. By focusing on local interactions, the MLRG algorithm reduces computational costs and improves the speed of parameter space exploration.\n",
    "\n",
    "2. Identification of Critical Points: The MLRG successfully automates the discovery of critical points, including unstable RG fixed points, using machine-learned RG flows. This ability to determine critical properties without relying on finite-size scaling enhances the analysis of complex physical systems.\n",
    "\n",
    "3. Controlled Convergence: The method exhibits controlled convergence, where the estimation of physical properties becomes increasingly accurate as the dimension of the latent space is increased. This feature ensures that predictions improve with the availability of computational resources.\n",
    "\n",
    "4. Improved Interpretability: The MLRG approach provides better interpretability compared to other machine-learning methods in RG, as it labels hidden spins with symmetry representations. This leads to more physically meaningful coupling parameters and RG rules, which are valuable for gaining insights in physical sciences.\n",
    "\n",
    "5. Potential for Future Research: The article highlights that while the current stochastic training of RBMs may introduce fluctuations and noise, future enhancements could involve replacing RBMs with tensor networks to improve stability and reliability. This could extend the MLRG's application to more complex spin models with larger internal symmetry groups.\n",
    "\n",
    "### Conclusion\n",
    "The authors conclude that the MLRG approach represents a significant advancement in the study of renormalization group (RG) techniques, integrating machine learning to enhance efficiency and accuracy in analyzing complex physical systems. By leveraging a multi-level, multi-model framework, MLRG not only facilitates the exploration of parameter spaces but also automates the identification of critical points, thus reducing the reliance on traditional methods that often involve cumbersome finite-size scaling.\n",
    "\n",
    "Moreover, the ability to provide interpretable results through the incorporation of symmetry representations enhances the method's applicability in the physical sciences. The authors acknowledge that the current stochastic training process of the RBMs introduces noise, which can affect the stability of the RG monotone network. However, they posit that future research could further improve this framework by employing tensor networks for deterministic training, thereby broadening the scope of the MLRG to encompass more intricate spin models.\n",
    "\n",
    "In summary, the MLRG approach not only addresses existing challenges in RG methodologies but also opens new avenues for understanding critical phenomena in statistical physics, emphasizing its potential as a valuable tool for scientific discovery."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c154018-4ba3-4afa-a676-4fa5bb7d36a5",
   "metadata": {},
   "source": [
    "## Reproducing the Results:\n",
    "\n",
    "\n",
    "__Code Availability__: The code is available in the GitHub repository at https://github.com/everettyou/mlrg.\n",
    "\n",
    "__Results__:\n",
    "\n",
    "The results are available in `MLRG.ipynb` file.\n",
    "\n",
    "Jtch : $$tensor([[ 0.1497, -0.2279, -1.1397,  0.0213,  0.2418],\n",
    "        [ 0.8748, -0.5543,  0.6796,  1.0219,  0.4357],\n",
    "        [ 0.0210,  2.0475, -1.0225,  1.1027, -0.1913],\n",
    "        ...,\n",
    "        [ 1.3544, -0.8154, -1.4709,  0.0993, -1.7124],\n",
    "        [-0.7736,  1.3139, -0.4054,  1.2131, -1.4269],\n",
    "        [ 1.0324, -0.3331, -0.2147, -1.4737, -0.1066]])$$\n",
    "        \n",
    "  \n",
    "**********************************************************************************************************************\n",
    "```python\n",
    "    for i in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    Jtch = mlrg.propose(Jtch, beta=5.,lamb=0.,mu=0.,steps=8)\n",
    "    loss = mlrg.loss(Jtch=Jtch, samples=5000, gibbssteps=50, cdsteps=5).mean(-1)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    import os\n",
    "\n",
    "    # Create the target directory if it doesn't exist\n",
    "    save_dir = \"./models/A1E/finetune\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    torch.save(mlrg.state_dict(), \"./models/A1E/\" + \"finetune/mlrg_A1E.pth\")\n",
    "    print(f'{i}: {loss.item()} {Jtch.abs().mean()}')\n",
    "    \n",
    "print(\"Finish\")\n",
    "```\n",
    "\n",
    "$$ 0: 0.08920170366764069 \\quad 0.7190833687782288 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb88a887-e857-4eca-a14f-a357f17dff80",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Wanda Hou and Yi-Zhuang You (16 October 2023). Machine learning renormalization group for statistical physics. Machine Learning: Science and Technology, 4(4), 045010. Published by IOP Publishing Ltd. https://doi.org/10.1088/2632-2153/ad0101\n",
    "\n",
    "2. Machine Learning Renormalization Group for Statistical Physics. Wanda Hou, Yi-Zhuang You (19 Jun 2023). Papers with Code. https://physics.paperswithcode.com/paper/machine-learning-renormalization-group-for\n",
    "\n",
    "3. GitHub Repository: everettyou/mlrg. (n.d.). https://github.com/everettyou/mlrg\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
